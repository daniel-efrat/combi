import OpenAI from "openai"
import {
  TranscriptionResponse,
  TranslationResponse,
  SummaryResponse,
  Language,
  SummaryLength,
} from "../types"
import { SUMMARY_LENGTHS } from "../constants"
import {
  WhisperConfig,
  WhisperResponse,
  WhisperSegment,
} from "@/lib/config/whisper"
import {
  convertToMp3,
  isAudioFile,
  isVideoFile,
  splitAudioFile,
  MAX_CHUNK_SIZE,
} from "@/lib/utils/file-processing"

// Check if we're in a browser environment
const isClient = typeof window !== "undefined"
const apiKey = isClient
  ? process.env.NEXT_PUBLIC_OPENAI_API_KEY
  : process.env.OPENAI_API_KEY

if (!apiKey) {
  throw new Error("OpenAI API key is not configured")
}

const openai = new OpenAI({
  apiKey,
  dangerouslyAllowBrowser: true,
})

// Maximum file size in bytes (25MB)
export const MAX_FILE_SIZE = 25 * 1024 * 1024

function formatBytes(bytes: number): string {
  const sizes = ["Bytes", "KB", "MB", "GB"]
  if (bytes === 0) return "0 Byte"
  const i = Math.floor(Math.log(bytes) / Math.log(1024))
  return `${Math.round(bytes / Math.pow(1024, i))} ${sizes[i]}`
}

type ProgressCallback = (stage: string, progress: number) => void

async function compressAudio(
  file: File,
  onProgress: ProgressCallback
): Promise<File> {
  try {
    console.log(`üéµ Starting compression for file: ${file.name}`)
    console.log(`üìä Original size: ${formatBytes(file.size)}`)

    onProgress("compressing", 0)
    const convertedFile = await convertToMp3(file)
    onProgress("compressing", 100)

    console.log(`üìä Compressed size: ${formatBytes(convertedFile.size)}`)
    console.log(
      `üìâ Compression ratio: ${(
        (1 - convertedFile.size / file.size) *
        100
      ).toFixed(1)}%`
    )

    return convertedFile
  } catch (error) {
    console.error("‚ùå Audio compression error:", error)
    throw error
  }
}

async function transcribeChunk(
  chunk: File,
  language: string,
  chunkIndex: number,
  totalChunks: number,
  onProgress: ProgressCallback
): Promise<WhisperResponse> {
  try {
    console.log(`üîÑ Processing chunk ${chunkIndex + 1}/${totalChunks}`)
    console.log(`üìä Chunk size: ${formatBytes(chunk.size)}`)

    const formData = new FormData()
    formData.append("file", chunk)
    formData.append("model", "whisper-1")
    formData.append("response_format", "verbose_json")
    if (language) formData.append("language", language)

    console.log(`üåê Sending request to OpenAI API for chunk ${chunkIndex + 1}`)
    const startTime = Date.now()

    try {
      const response = await fetch(
        "https://api.openai.com/v1/audio/transcriptions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            // Remove CORS headers from client request
          },
          // Remove credentials and mode
          body: formData,
        }
      )

      const endTime = Date.now()
      console.log(`‚è±Ô∏è API call took ${(endTime - startTime) / 1000}s`)

      if (!response.ok) {
        const errorText = await response.text()
        console.error(`‚ùå API error response:`, errorText)

        // Parse error if possible
        try {
          const errorJson = JSON.parse(errorText)
          throw new Error(
            errorJson.error?.message ||
              `Transcription failed: ${response.statusText}`
          )
        } catch {
          throw new Error(
            `Transcription failed: ${response.statusText}. ${errorText}`
          )
        }
      }

      const data = await response.json()
      const progress = ((chunkIndex + 1) / totalChunks) * 100
      onProgress("transcribing", progress)

      console.log(`‚úÖ Successfully transcribed chunk ${chunkIndex + 1}`)
      return data
    } catch (error) {
      if (error instanceof TypeError && error.message === "Failed to fetch") {
        console.log(
          `üîÑ Network error, retrying chunk ${chunkIndex + 1} in 2s...`
        )
        await new Promise((resolve) => setTimeout(resolve, 2000))
        return transcribeChunk(
          chunk,
          language,
          chunkIndex,
          totalChunks,
          onProgress
        )
      }
      throw error
    }
  } catch (error) {
    console.error(`‚ùå Error transcribing chunk ${chunkIndex}:`, error)
    throw error
  }
}

export async function transcribeAudio(
  file: File,
  language: string,
  onProgress: ProgressCallback
): Promise<WhisperResponse> {
  try {
    console.log(`\nüé¨ Starting transcription process for: ${file.name}`)
    console.log(`üìä Initial file size: ${formatBytes(file.size)}`)
    console.log(`üåç Language: ${language}`)

    // Analysis stage
    onProgress("analyzing", 0)
    const needsCompression =
      file.size > MAX_CHUNK_SIZE ||
      isVideoFile(file) ||
      (isAudioFile(file) && file.type !== "audio/mpeg")
    console.log(`üîç File type: ${file.type}`)
    console.log(`üìù Needs compression: ${needsCompression}`)
    onProgress("analyzing", 100)

    // Compression stage if needed
    let processedFile: File
    if (needsCompression) {
      console.log("üîÑ Starting compression...")
      processedFile = await compressAudio(file, onProgress)
    } else {
      processedFile = file
    }

    // Splitting stage for large files
    onProgress("splitting", 0)
    console.log(`\nüìÇ Checking if file needs splitting...`)
    console.log(`üìä Processed file size: ${formatBytes(processedFile.size)}`)
    console.log(`üìä Max chunk size: ${formatBytes(MAX_CHUNK_SIZE)}`)

    let chunks: File[]
    if (processedFile.size > MAX_CHUNK_SIZE) {
      console.log("‚úÇÔ∏è Splitting file into chunks...")
      chunks = await splitAudioFile(processedFile)
      console.log(`üì¶ Created ${chunks.length} chunks`)
      chunks.forEach((chunk, index) => {
        console.log(`  Chunk ${index + 1}: ${formatBytes(chunk.size)}`)
      })
    } else {
      chunks = [processedFile]
      console.log("üìÑ Using single file (no splitting needed)")
    }
    onProgress("splitting", 100)

    // Transcription stage
    console.log("\nüéØ Starting transcription...")
    onProgress("transcribing", 0)
    const results = await Promise.all(
      chunks.map((chunk, index) =>
        transcribeChunk(chunk, language, index, chunks.length, onProgress)
      )
    )

    // Merging stage
    console.log("\nüîÑ Merging results...")
    onProgress("merging", 0)
    const mergedResult: WhisperResponse = {
      text: results.map((r) => r.text).join(" "),
      segments: results.flatMap((result, chunkIndex) =>
        result.segments.map((segment: any) => ({
          id: `segment-${chunkIndex}-${segment.id}`,
          start: segment.start + chunkIndex * (30 * 60),
          end: segment.end + chunkIndex * (30 * 60),
          text: segment.text,
        }))
      ),
    }
    onProgress("merging", 100)

    console.log("‚úÖ Transcription complete!")
    console.log(`üìù Total segments: ${mergedResult.segments.length}`)
    console.log(`üìä Total text length: ${mergedResult.text.length} characters`)

    return mergedResult
  } catch (error) {
    console.error("‚ùå Transcription error:", error)
    throw error
  }
}

export async function translateText(
  text: string,
  targetLanguage: Language
): Promise<TranslationResponse> {
  const response = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      {
        role: "system",
        content: `You are a professional translator. Translate the following text to ${targetLanguage} while maintaining the original meaning and tone. Provide only the translation without any additional comments.`,
      },
      {
        role: "user",
        content: text,
      },
    ],
  })

  return {
    text: response.choices[0].message.content || "",
    language: targetLanguage,
  }
}

export async function summarizeText(
  text: string,
  length: SummaryLength
): Promise<SummaryResponse> {
  const response = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      {
        role: "system",
        content: `You are an expert at summarizing content. Create ${SUMMARY_LENGTHS[length]} of the following text. Focus on the key points and maintain the original meaning. Provide only the summary without any additional comments.`,
      },
      {
        role: "user",
        content: text,
      },
    ],
  })

  return {
    text: response.choices[0].message.content || "",
    length,
  }
}
